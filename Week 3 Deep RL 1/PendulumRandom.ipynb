{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PendulumRandom.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtP9o6f55lTsJU4lm4RocQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chambai/Deep_Learning_Course/blob/main/Week%203%20Deep%20RL%201/PendulumRandom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_2rZAsR2Glb"
      },
      "source": [
        "# Pendulum Random Exercise\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LflWMlOH2JLd"
      },
      "source": [
        "Create and environment called **Pendulum-v0**.  This environment is from the **classic control** group of environments.\r\n",
        "\r\n",
        "The pendulum starts in a random position, and the goal is to swing it up so it stays upright. When it is upright, the angle of the pole is zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc6Zt5eX2Sg7"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj8LF_N-DDk_"
      },
      "source": [
        "The reward in the Pendulum environment is the angle that the pole gets to, therefore the aim is to get a reward of zero meaning that the pole is upright"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKK5DA390wRe"
      },
      "source": [
        "# Try random actions to try and get Pendulum to the upright position\r\n",
        "The following cell is just to get Colab to render the Pendulum environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQjbHRlVzK6m"
      },
      "source": [
        "# code to render the CartPole environment in Colab\r\n",
        "!sudo apt-get install -y xvfb ffmpeg\r\n",
        "!pip install 'imageio==2.4.0'\r\n",
        "!pip install pyvirtualdisplay\r\n",
        "\r\n",
        "from __future__ import absolute_import, division, print_function\r\n",
        "\r\n",
        "import base64\r\n",
        "import imageio\r\n",
        "import IPython\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import PIL.Image\r\n",
        "import pyvirtualdisplay\r\n",
        "from IPython.display import clear_output\r\n",
        "from time import sleep\r\n",
        "\r\n",
        "# Set up a virtual display for rendering OpenAI gym environments.\r\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\r\n",
        "\r\n",
        "# import gym and test that the rendering works\r\n",
        "import gym\r\n",
        "# make the pendulum environment\r\n",
        "env = gym.make(\"???\")   # update to load the Pendulum-v0 environment\r\n",
        "env.reset()\r\n",
        "plt.imshow(env.render(mode='rgb_array'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUOuU7nLG_th"
      },
      "source": [
        "Load the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BScvK9DJG-rv"
      },
      "source": [
        "# import gym and test that the rendering works\r\n",
        "import gym\r\n",
        "# make the pendulum environment\r\n",
        "env = gym.make(\"Pendulum-v0\")   # update to load the Pendulum-v0 environment\r\n",
        "env.reset()\r\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wapzjbjbDkUC"
      },
      "source": [
        "Investigate the `action_space` and `observation_space` of the `Pendulum-v0` environment.  How many actions does it have? How many observations does it have? Are they continuous or discrete values?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0cSj9dJDyon"
      },
      "source": [
        "# investigate the action_space and observation_space here\r\n",
        "print(env.???)\r\n",
        "print(env.???)\r\n",
        "\r\n",
        "print('action space bounds')\r\n",
        "print(env.???)\r\n",
        "print(env.???)\r\n",
        "\r\n",
        "print('observation space bounds')\r\n",
        "print(env.???)\r\n",
        "print(env.???)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn9CmZBQPq3z"
      },
      "source": [
        "Run one episode of Pendulum using random actions.  If it takes too long to run, set `showImage = False` in the cell below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ldienaz69x"
      },
      "source": [
        "# the following code is the agent\r\n",
        "# initialise the agent by setting the reward and total steps to zero and the\r\n",
        "total_reward = 0.0\r\n",
        "total_steps = 0\r\n",
        "obs = env.reset()\r\n",
        "showImage = True\r\n",
        "\r\n",
        "step_num = 1\r\n",
        "while True:\r\n",
        "    clear_output()\r\n",
        "    print('step number: %s'%(step_num))\r\n",
        "    action = env.action_space.sample()        # gets a random action from the environment (either 1 or 0)\r\n",
        "    print('action: %s'%(action))              # print out the action we have received\r\n",
        "    obs, reward, done, _ = env.step(action)   # execute the action via the step method\r\n",
        "                                              # returns the observation, reward and boolean indicating if the episode has finished\r\n",
        "                                              # (the fourth parameter is for diagnostic purposes and we do not need to know about it for this tutorial)\r\n",
        "    print('obs: %s'%(obs))                    # print observation - array of length 4\r\n",
        "    print('reward: %s'%(reward))              # see what the reward was\r\n",
        "    print('done: %s'%(done))                  # see if the environment has ended the episode i.e. you may have tipped the pole over)\r\n",
        "                                              # (boolean: False means episode still running. True means episode ended)\r\n",
        "    if showImage:\r\n",
        "      plt.imshow(env.render(mode='rgb_array'))  # render the observations for demo purposes. Massively slows it down so set showImage to False to speed it up\r\n",
        "      plt.show()                                # plot the image\r\n",
        "      sleep(1)                                  # sleep the thread so that we can see the image\r\n",
        "    \r\n",
        "    total_reward += reward                    # sum the rewards                 \r\n",
        "    total_steps += 1                          # increment total number of steps\r\n",
        "    if done:\r\n",
        "        break\r\n",
        "    step_num += 1\r\n",
        "\r\n",
        "print(\"Episode done in %d steps, total reward %.2f\" % (total_steps, total_reward))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rVAETslP5mG"
      },
      "source": [
        "Run multiple episodes of Pendulum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ngo9OMQJO3P"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# set the number of episodes to 500\r\n",
        "episodes = 500\r\n",
        "# set up an empty array so that the reward for each episode can be stored\r\n",
        "total_rewards=np.zeros(episodes)\r\n",
        "\r\n",
        "for episode_num in range(episodes):\r\n",
        "  # the following code is the agent\r\n",
        "  # initialise the agent by setting the reward and total steps to zero and the\r\n",
        "  total_reward = 0.0\r\n",
        "  total_steps = 0\r\n",
        "  obs = env.reset()\r\n",
        "  showImage = False\r\n",
        "\r\n",
        "  n = 1\r\n",
        "  while True:\r\n",
        "      action = env.action_space.sample()        # gets a random action from the environment (either 1 or 0)\r\n",
        "      obs, reward, done, _ = env.step(action)   # execute the action via the step method\r\n",
        "                                                # returns the observation, reward and boolean indicating if the episode has finished\r\n",
        "                                                # (the fourth parameter is for diagnostic purposes and we do not need to know about it for this tutorial)\r\n",
        "\r\n",
        "      # print out the information in one line\r\n",
        "      print(\"Episode %d, step %d, action %d, reward %d, Done=%s\" % (episode_num, n, action, reward, done))\r\n",
        "\r\n",
        "      if showImage:\r\n",
        "        plt.imshow(env.render(mode='rgb_array'))  # render the observations for demo purposes. Massively slows it down so set showImage to False to speed it up\r\n",
        "        plt.show()                                # plot the image\r\n",
        "        sleep(1)                                  # sleep the thread so that we can see the image\r\n",
        "      \r\n",
        "      total_reward += reward                    # sum the rewards                 \r\n",
        "      total_steps += 1                          # increment total number of steps\r\n",
        "      if done:\r\n",
        "          break\r\n",
        "      n += 1\r\n",
        "\r\n",
        "  print(\"Episode %d done in %d steps, total reward %.2f\" % (episode_num, total_steps, total_reward))\r\n",
        "  total_rewards[episode_num]=total_reward       # store the total reward for this episode\r\n",
        "  episode_num += 1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUUcP1ItbqZ0"
      },
      "source": [
        "Plot the reward for each episode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JVSu5Lybgky"
      },
      "source": [
        "plt.xlabel('Reward')\r\n",
        "plt.ylabel('Episode Steps')\r\n",
        "plt.plot(total_rewards)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHqOHsfFFQ2d"
      },
      "source": [
        "We have shown how we have different action and observation spaces and rewards for different environments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JWhQ_60QWQi"
      },
      "source": [
        "## Optional: Investigate the action and observation spaces from other environments from the classic control group of environments\r\n",
        "https://gym.openai.com/envs/#classic_control "
      ]
    }
  ]
}