{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AmazonReviewsTextSumm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chambai/Deep_Learning_Course/blob/main/Week%204%20DL%20NLP%202/AmazonReviewsTextSumm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAJ0UqjYmaIj"
      },
      "source": [
        "# Text Summarization of Amazon reviews\r\n",
        "Adapted from https://towardsdatascience.com/lets-give-some-attention-to-summarising-texts-d0af2c4061d1 and https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uta24rZgWgrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8318d3ef-0920-4726-ab42-6ead6133762d"
      },
      "source": [
        "# load python libraries\n",
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import re           \n",
        "import os\n",
        "from bs4 import BeautifulSoup     # pulls data out of XML and HTML files\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "!pip install wget\n",
        "import wget\n",
        "import nltk\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFrjO5PTnd6Y"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzJrRVH5dgOm"
      },
      "source": [
        "# load the reviews from a csv file into Pandas\n",
        "data=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Deep Learning Course CMP7225 2021/Week 4 DL NLP 2/data/AmazonReviews.csv\",nrows=100000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYnP9oR30QKV",
        "outputId": "94e8ea42-fe5d-4a8b-a5b2-cb683f914b38"
      },
      "source": [
        "# see how many entries there are\r\n",
        "print(data['Text'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TIv2muT0AmC",
        "outputId": "34849532-18e5-4a3f-c9a5-856f0031fae7"
      },
      "source": [
        "# limit the data for this exercise otherwise it will take too long to train\r\n",
        "# let's limit the data from 100,000 to 10,000\r\n",
        "data = data[:10000]\r\n",
        "print(data['Text'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "dY8oGPq60B_a",
        "outputId": "9fffdcb6-840b-4c7b-e8b1-be4d1b9d16e4"
      },
      "source": [
        "# Display some of the data\r\n",
        "data[['Text','Summary']].sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2884</th>\n",
              "      <td>French roast my green mountain is my favorite every day K-cup. Its a good coffee... bold yet smooth. NOT BURNT (I hate Peets and Starbucks because they taste like the burn the beans). If you like ...</td>\n",
              "      <td>My FAVORITE K-Cup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1268</th>\n",
              "      <td>This tea is so helpful for congestion and it tastes great too.  Make sure you let it steep as long as the directions say.  It really seems to help you to feel better.</td>\n",
              "      <td>Great tasting tea for Cold &amp; Flu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6350</th>\n",
              "      <td>These are the best Jerky Strips I have ever tasted. Our family has been eating them for years and they are typically a Christmas delight.</td>\n",
              "      <td>Yummy Jerky Strips</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6557</th>\n",
              "      <td>We have a 3 year old Maltese that we used to shower with Greenies (1-2 a day) even though it says to limit them to one per day.  The last time we took him to the vet, we told her what kind of food...</td>\n",
              "      <td>Great Greenie alternative!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6721</th>\n",
              "      <td>No harsh after taste, no tangible negatives.  It just doesn't have the \"bite\" that I crave from other carbonated beverages like ginger ale or root beer.  It's a good option for a healthful drink w...</td>\n",
              "      <td>Nothing earth-shattering; I enjoyed it, though it lacks bite</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                         Text                                                       Summary\n",
              "2884  French roast my green mountain is my favorite every day K-cup. Its a good coffee... bold yet smooth. NOT BURNT (I hate Peets and Starbucks because they taste like the burn the beans). If you like ...                                             My FAVORITE K-Cup\n",
              "1268                                   This tea is so helpful for congestion and it tastes great too.  Make sure you let it steep as long as the directions say.  It really seems to help you to feel better.                              Great tasting tea for Cold & Flu\n",
              "6350                                                                These are the best Jerky Strips I have ever tasted. Our family has been eating them for years and they are typically a Christmas delight.                                            Yummy Jerky Strips\n",
              "6557  We have a 3 year old Maltese that we used to shower with Greenies (1-2 a day) even though it says to limit them to one per day.  The last time we took him to the vet, we told her what kind of food...                                    Great Greenie alternative!\n",
              "6721  No harsh after taste, no tangible negatives.  It just doesn't have the \"bite\" that I crave from other carbonated beverages like ginger ale or root beer.  It's a good option for a healthful drink w...  Nothing earth-shattering; I enjoyed it, though it lacks bite"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R9o-P9kf1YH"
      },
      "source": [
        "# Remove any duplicate entries in the data\n",
        "data.drop_duplicates(subset=['Text'],inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuOhs5GLf3ep"
      },
      "source": [
        "# map words to colloquial terms\n",
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj2aY36sgezy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9761d3f1-b9f5-4370-ee48-e10792fff367"
      },
      "source": [
        "# print out the first 10 entries in the data to view it to decide what to do for data cleaning\r\n",
        "data['Text'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...\n",
              "1             Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
              "2    This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...\n",
              "3    If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...\n",
              "4                                                               Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
              "5    I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there wa...\n",
              "6    This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, ...\n",
              "7                                                               This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!!\n",
              "8                                                                        Right now I'm mostly just sprouting this so my cats can eat the grass. They love it. I rotate it around with Wheatgrass and Rye too\n",
              "9                                                                  This is a very healthy dog food. Good for their digestion. Also good for small puppies. My dog eats her required amount at every feeding.\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKrNNNhUSpKG",
        "outputId": "dc1c2b1e-d773-485b-c153-97b9e9a7c24d"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXq2cfrJgjeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4fbdba-3c72-4f29-a483-2fd6dabd43e5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')  # donload the stopwords library for use by NLTK\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "# create a function to clean the text.  Remove whiteapce, html characters, punctuation etc...\n",
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])  \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>=3:                  #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()\n",
        "\n",
        "# store the cleaned text in a list\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz_oq8hig5r8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebe63d9-75d0-4aff-8fc4-83699301a899"
      },
      "source": [
        "# print out the first 10 items of the summaries\r\n",
        "data['Summary'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                            Good Quality Dog Food\n",
              "1                                Not as Advertised\n",
              "2                            \"Delight\" says it all\n",
              "3                                   Cough Medicine\n",
              "4                                      Great taffy\n",
              "5                                       Nice Taffy\n",
              "6    Great!  Just as good as the expensive brands!\n",
              "7                           Wonderful, tasty taffy\n",
              "8                                       Yay Barley\n",
              "9                                 Healthy Dog Food\n",
              "Name: Summary, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKDPMZy9rD2P"
      },
      "source": [
        "The summaries contain whitespaces and quote marks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWba3pHOhiSX"
      },
      "source": [
        "# create a function to clean the summary text\n",
        "def summary_cleaner(text):\n",
        "    newString = re.sub('\"','', text)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = newString.lower()\n",
        "    tokens=newString.split()\n",
        "    newString=''\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                 \n",
        "            newString=newString+i+' '  \n",
        "    return newString\n",
        "\n",
        "# Call the summary_cleaner function and store the cleaned summaries in a list\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(summary_cleaner(t))\n",
        "\n",
        "# store the cleaned text and summaries in a dictionary\n",
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n",
        "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
        "# drop rows with null values\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX3WYiXphmc8"
      },
      "source": [
        "# add the text _START_ and _END_ to the summaries to easily identify they are the summaries\n",
        "data['cleaned_summary'] = data['cleaned_summary'].apply(lambda x : '_START_ '+ x + ' _END_')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbWj6g3Mhu8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a09eaa-645c-4db9-c3c1-998058bb4a9c"
      },
      "source": [
        "# print the first 5 reviews and their summaries\n",
        "for i in range(5):\n",
        "    print(\"Review:\",data['cleaned_text'][i])\n",
        "    print(\"Summary:\",data['cleaned_summary'][i])\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
            "Summary: _START_ good quality dog food  _END_\n",
            "\n",
            "\n",
            "Review: product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
            "Summary: _START_ not as advertised  _END_\n",
            "\n",
            "\n",
            "Review: confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
            "Summary: _START_ delight says it all  _END_\n",
            "\n",
            "\n",
            "Review: looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal\n",
            "Summary: _START_ cough medicine  _END_\n",
            "\n",
            "\n",
            "Review: great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
            "Summary: _START_ great taffy  _END_\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4BNpxgiiXKf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "3c8968d7-4001-4553-e7df-036705124f07"
      },
      "source": [
        "# investigate the distribution of the length of the text in the data\n",
        "# to help fix the max length of the sequence\n",
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa-vAqvLiX_1"
      },
      "source": [
        "# from histograms, decide on a text review length of 80 and a summary length of 10\n",
        "max_len_text=80\n",
        "max_len_summary=10\n",
        "\n",
        "# split the data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(data['cleaned_text'],data['cleaned_summary'],test_size=0.1,random_state=0,shuffle=True) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJq0rPagif_W"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
        "\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4qr66Wtikv1"
      },
      "source": [
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert summary sequences into integer sequences\n",
        "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4E8rTFejJG4"
      },
      "source": [
        "# Don't worry about understanding the code in this cell.  \n",
        "# It sets up an attention layer you just need to know what an attention layer is \n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMlw1Nzcio4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3147d2-b4c7-4e35-b0f5-77366ad5037f"
      },
      "source": [
        "# create the model\n",
        "# this has to be created with the Keras Functional Model instead of the Sequentail\n",
        "# model to be able to accomodate the Attention layer\n",
        "from keras import backend as K \n",
        "K.clear_session() \n",
        "latent_dim = 500 \n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "# TimeDistributed allows you to apply a layer to every temporal slice of an input\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 80, 500)      8455000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 80, 500), (N 2002000     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 80, 500), (N 2002000     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 500)    2125000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 80, 500), (N 2002000     lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 4250)   4254250     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 23,342,750\n",
            "Trainable params: 23,342,750\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fUJoaFAiwUb"
      },
      "source": [
        "# compile the model\r\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJadRMArlgRX"
      },
      "source": [
        "# implement early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbYlG4bXljdD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "a81d799c-26e2-40a2-f063-f0c2ded8d7b3"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=10,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0d4d31710099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQf1v5WhqLLg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "aac276e2-8bd5-46ae-83a3-9850af71ac6b"
      },
      "source": [
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='test') \n",
        "pyplot.legend() \n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlSTzEbnskcd"
      },
      "source": [
        "\n",
        "reverse_target_word_index=y_tokenizer.index_word \n",
        "reverse_source_word_index=x_tokenizer.index_word \n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thX0Ep0Ssnd1"
      },
      "source": [
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtU0wU8gsuz1"
      },
      "source": [
        "# function that predicts the outputs\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    print('input_seq: {}, e_out: {} '.format(input_seq,e_out))\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        print(\"sampled_token:\",sampled_token)\n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        # stop_condition = True\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLyRVENRs2Ay"
      },
      "source": [
        "# function to transform summary sequence of numbers into its words\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "# function to transform text sequence of numbers into its words\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppFD9D58zO8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323f89b2-c4e2-4a73-fb90-9f28bee6a914"
      },
      "source": [
        "  # pick a sequence from the validation data\n",
        "  print(\"Review:\",seq2text(x_val[3]))\n",
        "\n",
        "  # display the original summary\n",
        "  print(\"Original summary:\",seq2summary(y_val[3]))\n",
        "\n",
        "  # get and display the predicted summary\n",
        "  print(\"Predicted summary:\",decode_sequence(x_val[3].reshape(1,max_len_text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: got lucky nonetheless think jerky strips best ever admit fact little salty nothing ice cold cola beer choice fix per tough five six right container soon opened could stop good chewing jaw none worse wear real jerky fans definitely worth trying update little research curious everyone thought jerky salty looked nutrition facts flavors original peppered contain sodium wood smoked teriyaki sodium thought others salty worried jerky salty try teriyaki highly recommend salty hint sweet teriyaki still nice pepper flavor well \n",
            "Original summary: misleading reviews \n",
            "input_seq: [[  72 3016 4603   61  557 1796   18   96 1076  282   19  378  245  354\n",
            "   441 3172 1005  412 1432  156 1648  649  711   89  491  545  371   38\n",
            "   720    2 1327 4802  576 1056 5808  182  557 1701  111  178  192 1094\n",
            "    19 1009 2690  290  115  557  378  438  700 1947   49  498 3617  550\n",
            "   454 2521 1763 3455  454  115  263  378 1414  557  378   30 3455  153\n",
            "    50  378  676   45 3455   56   69  469    9   29]], e_out: [[[ 2.4251994e-03 -1.9378768e-03 -2.5111106e-03 ... -8.6448644e-04\n",
            "    3.2311240e-03  1.0900920e-03]\n",
            "  [ 4.1286731e-03 -1.9532905e-04 -3.3517450e-03 ... -1.7249510e-03\n",
            "    4.6405755e-03  2.7880203e-03]\n",
            "  [ 3.8053563e-03  5.3550918e-03 -1.4131978e-03 ... -1.0360753e-03\n",
            "    4.6564187e-03  5.7535577e-03]\n",
            "  ...\n",
            "  [ 5.0324416e-01 -1.3713096e-01 -2.3622186e-01 ... -5.2387130e-01\n",
            "    3.3073664e-01 -5.1212794e-01]\n",
            "  [ 4.9823895e-01 -1.4406328e-01 -2.4869002e-01 ... -5.2386230e-01\n",
            "    3.3827066e-01 -5.1065969e-01]\n",
            "  [ 4.9357903e-01 -1.4890689e-01 -2.5779006e-01 ... -5.2181017e-01\n",
            "    3.4844655e-01 -5.0494045e-01]]] \n",
            "sampled_token: the\n",
            "sampled_token: the\n",
            "sampled_token: the\n",
            "sampled_token: the\n",
            "sampled_token: the\n",
            "sampled_token: the\n",
            "sampled_token: the\n",
            "sampled_token: the\n",
            "sampled_token: the\n",
            "Predicted summary:  the the the the the the the the the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KiQtQiczjdO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}