{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UseDNNArchitecture_Sln.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chambai/Deep_Learning_Course/blob/main/Week%202%20DL%20Image%20Analysis%202/UseDNNArchitecture_Sln.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y-BHINGf5Cw"
      },
      "source": [
        "#Using Pre-Existing DNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED-dq48CtXeb"
      },
      "source": [
        "# load the mnist dataset from keras\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import datasets\r\n",
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\r\n",
        "\r\n",
        "# Normalize pixel values between 0 and 1\r\n",
        "x_train = x_train.astype('float32') / 255.0\r\n",
        "x_test = x_test.astype('float32') / 255.0\r\n",
        "\r\n",
        "# One hot encode the output data\r\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\r\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4z3280-zw2h"
      },
      "source": [
        "##Create a VGG16 DNN architecture, compile, fit with CIFAR10 data and plot the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COb2zvL5uyB1"
      },
      "source": [
        "# load a pre-existing model (DOesn't use the weights from the trained network, just the architectue)\r\n",
        "model = tf.keras.applications.VGG16(\r\n",
        "    weights=None, \r\n",
        "    include_top=True, \r\n",
        "    classes=10,\r\n",
        "    input_shape=(32,32,3) # change the input shape of the network to match the dataset\r\n",
        ")\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# same optimiser as used in the paper\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "history = model.fit(\r\n",
        "    x=x_train,\r\n",
        "    y=y_train,\r\n",
        "    validation_split=0.1,\r\n",
        "    batch_size=32,\r\n",
        "    epochs=10,\r\n",
        "    verbose=1,\r\n",
        "    shuffle=True) \r\n",
        "\r\n",
        "# summarize the history for accuracy\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train','test'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# summarize the history for loss\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train','test'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm2nJZ1bMvHN"
      },
      "source": [
        "#Try other DNNs from Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxY7KKiMM4_7"
      },
      "source": [
        "# load a pre-existing model (DOesn't use the weights from the trained network, just the architectue)\r\n",
        "model = tf.keras.applications.MobileNetV3Small(\r\n",
        "    weights=None, \r\n",
        "    include_top=True, \r\n",
        "    classes=10,\r\n",
        "    input_shape=(32,32,3) # change the input shape of the network to match the dataset\r\n",
        ")\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# same optimiser as used in the paper\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "history = model.fit(\r\n",
        "    x=x_train,\r\n",
        "    y=y_train,\r\n",
        "    validation_split=0.1,\r\n",
        "    batch_size=32,\r\n",
        "    epochs=10,\r\n",
        "    verbose=1,\r\n",
        "    shuffle=True) \r\n",
        "\r\n",
        "# summarize the history for accuracy\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train','test'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# summarize the history for loss\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train','test'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}