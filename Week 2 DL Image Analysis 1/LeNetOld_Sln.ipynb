{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNetOld_Sln.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chambai/Deep_Learning_Course/blob/main/Week%202%20DL%20Image%20Analysis%201/LeNetOld_Sln.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmnLNW6X9Qx0"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\r\n",
        "\r\n",
        "# download mnist data and split into train and test sets\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "# data pre-processing - we need to reshape to specify a channel of 1 on the end of the\r\n",
        "# data to signify that there is one channel as it is a grayscale image\r\n",
        "x_train = x_train.reshape(60000,28,28,1)\r\n",
        "x_test = x_test.reshape(10000,28,28,1)\r\n",
        "\r\n",
        "# one-hot encode the train and test target columns\r\n",
        "from keras.utils import to_categorical\r\n",
        "y_train = to_categorical(y_train)\r\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n46xOacd7Qyr"
      },
      "source": [
        "# create the model\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, AveragePooling2D, Dropout\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(filters=6, kernel_size=3, padding='same', activation='tanh', input_shape=(28,28,1)))\r\n",
        "model.add(AveragePooling2D(2))\r\n",
        "model.add(Conv2D(filters=16, kernel_size=5, padding='valid', activation='tanh'))\r\n",
        "model.add(AveragePooling2D(2))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(units=120, activation='tanh'))\r\n",
        "model.add(Dense(units=84, activation='tanh'))\r\n",
        "model.add(Dense(units=10, activation = 'softmax'))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# compiling the model\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# train the model\r\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XqnWmhaPjhs"
      },
      "source": [
        "# plot the history of the training\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# summarize the history for accuracy\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train','test'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# summarize the history for loss\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train','test'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}